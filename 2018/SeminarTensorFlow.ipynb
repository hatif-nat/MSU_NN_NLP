{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перед началом работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. инструкция по установке\n",
    "\n",
    "https://www.tensorflow.org/install/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезные ссылки:\n",
    "\n",
    "https://web.stanford.edu/class/cs20si/syllabus.html\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приступим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем сложить два числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.add(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и посмотрим результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_3:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в результате мы получам не число, а ссылку на узел в графе вычеслений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все переменные вычисляются в сессии - и только в том случае, если вы указали, что хотите посчитать их. До вычисления переменных только граф вычислений. Промежуточные результаты не вычисляются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "a_res = sess.run(a)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим вычесленное значение узла графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print (a_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не пишите так!! вы заменяете ссылку на узел графа вычислений на число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = sess.run(a)\n",
    "#     a_res = sess.run(a)\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим более сложный граф вычислений и посмотрим на него в TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в TensorFlow по умолчанию используется дефолтный граф вычислений. Добавим в него более сложный подграф и сохраним его содержимое в папку ./graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим с помощью следующей команды, запущенной из консоли: \n",
    "\n",
    "tensorboard --logdir=\"./graphs\" --port 6006\n",
    "\n",
    "Далее открываем localhost:6006\n",
    "\n",
    "И смотрим:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pictures_for_tf_sem/pic1.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что названия вершин генерируются автоматически исходя из типов операций в этой вершине. Для лучшей читаемости графа лучше называть переменные самому. В примеру именеим слоя: input, conv, linear и т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(2, name='a')\n",
    "b = tf.constant(3, name='b')\n",
    "x = tf.add(a, b, name='add')\n",
    "\n",
    "x = tf.constant(2, name='input_word')\n",
    "y = tf.constant(2, name='input_char')\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op, name='output')\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pictures_for_tf_sem/pic2.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "\n",
    "В TensorFlow вы имеете дело со следующими типами переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1, 2], name='a')\n",
    "b = tf.constant([[0, 1], [2, 3]], name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tf.Variable(2, name=\"scalar\")\n",
    "m = tf.Variable([[0, 1], [2, 3]], name=\"matrix\") \n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "W_constant = tf.Variable(tf.zeros([784,10]), trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания изменяемых переменных используйте get_variable. Она имеет доступ в пространству имен и не позволит созвать вам уже существующую переменную с таким именем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tf.get_variable(\"scalar\", initializer=tf.constant(2))\n",
    "m = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\n",
    "W = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable - это класс со множеством доступных операций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "x = tf.Variable(...) \n",
    "\n",
    "x.initializer # init op\n",
    "\n",
    "x.value() # read op\n",
    "\n",
    "x.assign(...) # write op\n",
    "\n",
    "x.assign_add(...) # and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scalar_2:0', 'scalar_3:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = tf.Variable(2, name=\"scalar\")\n",
    "one_more_scalar = tf.Variable(2, name=\"scalar\")\n",
    "scalar.name, one_more_scalar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable scalar already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\dima\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\dima\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\dima\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-608e9b4acae0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mone_more_scalar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"scalar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1295\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1298\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1299\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1091\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    437\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    406\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    745\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 747\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    748\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable scalar already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\dima\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\dima\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\dima\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "one_more_scalar = tf.get_variable(initializer=tf.constant(2), name=\"scalar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.get_variable(\"vector\", initializer=tf.constant([0, 1, 3]))\n",
    "yav = tf.get_variable(\"yet_anoter_one_vector\", initializer=tf.constant([4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(vec):\n",
    "    w = tf.Variable(tf.random_normal((3,3)), name='weights')\n",
    "    b = tf.Variable(tf.zeros((3,)), name='biases')\n",
    "    return tf.matmul(vec, w) + b\n",
    "\n",
    "linear1 = linear(v)\n",
    "linear2 = linear(yav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(vec):\n",
    "    w = tf.get_variable(\"weights\", (3,3), initializer=tf.random_normal_initializer())\n",
    "    b = tf.get_variable(\"biases\", (3,), initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(vec, w) + b\n",
    "linear1 = linear(v)\n",
    "linear2 = linear(yav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интерактив  \n",
    "## В чем разница между 2 последними окошками?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(vec):\n",
    "    w = tf.get_variable(\"weights\", (3,3), initializer=tf.random_normal_initializer())\n",
    "    b = tf.get_variable(\"biases\", (3,), initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(vec, w) + b\n",
    "\n",
    "with tf.variable_scope('two_linears') as scope:\n",
    "    linear1 = linear(v)\n",
    "    scope.reuse_variables()\n",
    "    linear2 = linear(yav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(vec):\n",
    "    w = tf.get_variable(\"weights\", (3,3), initializer=tf.random_normal_initializer())\n",
    "    b = tf.get_variable(\"biases\", (3,), initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(vec, w) + b\n",
    "\n",
    "with tf.variable_scope('linear1', reuse=tf.AUTO_REUSE) as scope:\n",
    "    linear1 = linear(v)\n",
    "with tf.variable_scope('linear2', reuse=tf.AUTO_REUSE) as scope:\n",
    "    linear2 = linear(yav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.google.com/presentation/d/1SJMsa4BdOFVRCPD9uwaAqDBYYfgbQcbOm7HaxRVpaaY/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разница между var_scope и name_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1:0\n",
      "my_scope/var2:0\n",
      "my_scope/Add:0\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"my_scope\"):\n",
    "    v1 = tf.get_variable(\"var1\", [1], dtype=tf.float32)\n",
    "    v2 = tf.Variable(1, name=\"var2\", dtype=tf.float32)\n",
    "    a = tf.add(v1, v2)\n",
    "\n",
    "print(v1.name)  # var1:0\n",
    "print(v2.name)  # my_scope/var2:0\n",
    "print(a.name)   # my_scope/Add:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_scope/var1:0\n",
      "my_scope_1/var2:0\n",
      "my_scope_1/Add:0\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"my_scope\"):\n",
    "    v1 = tf.get_variable(\"var1\", [1], dtype=tf.float32)\n",
    "    v2 = tf.Variable(1, name=\"var2\", dtype=tf.float32)\n",
    "    a = tf.add(v1, v2)\n",
    "\n",
    "print(v1.name)  # my_scope/var1:0\n",
    "print(v2.name)  # my_scope/var2:0\n",
    "print(a.name)   # my_scope/Add:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_scope/var:0\n",
      "var_scope/var:0\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"foo\"):\n",
    "    with tf.variable_scope(\"var_scope\"):\n",
    "        v = tf.get_variable(\"var\", [1])\n",
    "with tf.name_scope(\"bar\"):\n",
    "    with tf.variable_scope(\"var_scope\", reuse=True):\n",
    "        v1 = tf.get_variable(\"var\", [1])\n",
    "assert v1 == v\n",
    "print(v.name)   # var_scope/var:0\n",
    "print(v1.name)  # var_scope/var:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "взято с https://stackoverflow.com/questions/35919020/whats-the-difference-of-name-scope-and-a-variable-scope-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед вычислением нужно инициализировать переменные заданными значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value big_matrix\n\t [[Node: _retval_big_matrix_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](big_matrix)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value big_matrix\n\t [[Node: _retval_big_matrix_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](big_matrix)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-75df8eb1ad92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value big_matrix\n\t [[Node: _retval_big_matrix_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](big_matrix)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно это сделать любым из трех приведённых ниже способов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(W))\n",
    "    \n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.variables_initializer([a, b]))\n",
    "    \n",
    "# W = tf.Variable(tf.zeros([784,10]))\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(W.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычилить значение переменной можно с помощью функции eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=(784, 10) dtype=float32_ref>\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W)\n",
    "    print (W.eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также следите, какие именно узлы графа вы исполняете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "s = tf.Variable(2, name=\"scalar\")\n",
    "s.assign(100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(s.initializer)\n",
    "    print(s.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "s = tf.Variable(2, name=\"scalar\")\n",
    "s_op = s.assign(100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(s.initializer)\n",
    "    sess.run(s_op)\n",
    "    print(s.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении мы каждый раз подаем новые значения входных данных и меток классов. Существует специальная переменная, в которую можно подавать на вход данные, которую не нужно инициализировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.  7.  8.]\n"
     ]
    }
   ],
   "source": [
    "# create a placeholder for a vector of 3 elements, type tf.float32\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "\n",
    "b = tf.constant([5, 5, 5], tf.float32)\n",
    "\n",
    "# use the placeholder as you would a constant or a variable\n",
    "c = a + b  # short for tf.add(a, b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(c))\n",
    "    \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c, {a: [2, 2, 3]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if в при создании графа вычислений должен зависеть от параметров, не меняющихся в процессе вычисления графа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выносите все в специальные узлы графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "z = tf.add(x, y)\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/normal_loading', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(10):\n",
    "        sess.run(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание: код ниже написан короче, но создает 10 лишних вершин в графе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/normal_loading', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(10):\n",
    "        sess.run(tf.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определить вид растения(Щестинистый, разноцветный, виргинский) по данным измерения  \n",
    "Длина наружной доли околоцветника (sepal length)  \n",
    "Ширина наружной доли околоцветника (sepal width)  \n",
    "Длина внутренней доли околоцветника (petal length)  \n",
    "Ширина внутренней доли околоцветника (petal width)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/5/56/Iris_dataset_scatterplot.svg \"Iris Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "picture from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load iris dataset (Ирисы Фишера)\n",
    "\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "def maybe_download():\n",
    "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
    "\n",
    "    return train_path, test_path\n",
    "\n",
    "def load_data(y_name='Species'):\n",
    "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
    "    train_path, test_path = maybe_download()\n",
    "\n",
    "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop(y_name)\n",
    "\n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop(y_name)\n",
    "\n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create generator\n",
    "def next_batch(X_data, Y_data, batch_size=10):\n",
    "    length = X_data.shape[0]\n",
    "    reduced_length = (length // batch_size) * batch_size\n",
    "    \n",
    "    X_data = X_data[:reduced_length].reshape([batch_size, -1, 4])\n",
    "    Y_data = Y_data[:reduced_length].reshape([batch_size, -1]) \n",
    "    \n",
    "    X_data = np.transpose(X_data, axes=(1, 0, 2))\n",
    "    Y_data = np.transpose(Y_data, axes=(1, 0))\n",
    "    for x_i, y_i in zip(X_data, Y_data):\n",
    "        yield x_i, y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create placeholders\n",
    "batch_size = 10\n",
    "\n",
    "#X = tf.placeholder(tf.float32, shape=[batch_size, 4], name = 'input')\n",
    "#Y = tf.placeholder(tf.int32, shape=[batch_size], name = 'output')\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4], name = 'input')\n",
    "Y = tf.placeholder(tf.int32, shape=[None], name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create simple network\n",
    "\n",
    "layer_size = 50\n",
    "\n",
    "# initialization - http://cs231n.github.io/neural-networks-2/#init\n",
    "initializer = tf.random_normal_initializer(stddev=np.sqrt(2/layer_size), mean=0.0)\n",
    "\n",
    "# create weight and bias\n",
    "with tf.variable_scope(name_or_scope='layer_1'):\n",
    "    w1 = tf.get_variable('weights', shape=[4,layer_size], initializer=initializer)\n",
    "    b1 = tf.get_variable('bias', shape=[layer_size], initializer=initializer)\n",
    "    output_from_layer = tf.nn.relu(tf.matmul(X, w1) + b1)\n",
    "\n",
    "    \n",
    "with tf.variable_scope(name_or_scope='layer_2'):\n",
    "    w2 = tf.get_variable('weights', shape=[layer_size,3], initializer=initializer)\n",
    "    b2 = tf.get_variable('bias', shape=[3], initializer=initializer)\n",
    "    Y_predicted = tf.matmul(output_from_layer, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use tf.reduce_mean for batches\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = Y_predicted, labels = Y), name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose optimizer to minimize loss\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAKE SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make summaries\n",
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.histogram('weights1', w1)\n",
    "tf.summary.histogram('bias1', b1)\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for name of summaries\n",
    "\n",
    "from datetime import datetime\n",
    "def time_str():\n",
    "    return datetime.now().replace(microsecond=0).isoformat().replace(':','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 8.166786253452301\n",
      "Epoch 19: 5.675806969404221\n",
      "Epoch 29: 4.412605345249176\n",
      "Epoch 39: 3.5488267093896866\n",
      "Epoch 49: 2.901623919606209\n",
      "Epoch 59: 2.4162718653678894\n",
      "Epoch 69: 2.0557584688067436\n",
      "Epoch 79: 1.787713535130024\n",
      "Epoch 89: 1.5863817557692528\n",
      "Epoch 99: 1.432706505060196\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # initialize the necessary variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter('./summuries%s' %time_str(), sess.graph)\n",
    "    \n",
    "    # train the model for 100 epochs\n",
    "    for i in range(100):\n",
    "        total_loss = 0\n",
    "        for x_i, y_i in next_batch(train_x.values, train_y.values):\n",
    "            summary, _, l = sess.run(\n",
    "                [merged,\n",
    "                 optimizer, \n",
    "                 loss],feed_dict= \n",
    "                {X:x_i, \n",
    "                 Y:y_i}) \n",
    "            \n",
    "            total_loss += l  \n",
    "        train_writer.add_summary(summary, global_step=i)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch {0}: {1}'.format(i, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see summaries in TensorBoard\n",
    "\n",
    "for example: tensorboard --logdir=\"./iris/summuries2018-03-29T14-08-35/\" --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test----------------------------------------\n",
      "predicted -- true\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "1 -- 0\n",
      "1 -- 2\n",
      "1 -- 2\n",
      "1 -- 0\n",
      "1 -- 0\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "1 -- 2\n",
      "1 -- 1\n",
      "1 -- 2\n",
      "1 -- 2\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "1 -- 2\n",
      "1 -- 2\n",
      "1 -- 1\n",
      "1 -- 2\n",
      "1 -- 0\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "1 -- 0\n",
      "1 -- 1\n",
      "1 -- 0\n",
      "1 -- 0\n",
      "1 -- 1\n",
      "1 -- 0\n",
      "1 -- 1\n"
     ]
    }
   ],
   "source": [
    "# test our model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print ('test' + '--'*20)\n",
    "    print ('predicted -- true')\n",
    "\n",
    "    for x_i, y_i in next_batch(test_x.values, test_y.values):\n",
    "        Y_pred = sess.run(\n",
    "            [Y_predicted],\n",
    "            feed_dict= \n",
    "            {X:x_i})\n",
    "        for index_i, Y_in_batch in enumerate(Y_pred[0]):\n",
    "#             print (Y_in_batch)\n",
    "            print ('{0} -- {1}'.format(np.argsort(Y_in_batch)[-1], y_i[index_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# why so bad results?\n",
    "# we test a network with random value in layers! because we initialized it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 7.990514516830444\n",
      "Epoch 19: 5.279015392065048\n",
      "Epoch 29: 4.149567157030106\n",
      "Epoch 39: 3.3766963183879852\n",
      "Epoch 49: 2.789305418729782\n",
      "Epoch 59: 2.3463463485240936\n",
      "Epoch 69: 2.0151787772774696\n",
      "Epoch 79: 1.7676478698849678\n",
      "Epoch 89: 1.580244705080986\n",
      "Epoch 99: 1.4356933198869228\n",
      "test----------------------------------------\n",
      "predicted -- true\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "0 -- 0\n",
      "2 -- 2\n",
      "2 -- 2\n",
      "0 -- 0\n",
      "0 -- 0\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "2 -- 2\n",
      "1 -- 1\n",
      "1 -- 2\n",
      "2 -- 2\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "2 -- 2\n",
      "2 -- 2\n",
      "1 -- 1\n",
      "2 -- 2\n",
      "0 -- 0\n",
      "1 -- 1\n",
      "1 -- 1\n",
      "0 -- 0\n",
      "1 -- 1\n",
      "0 -- 0\n",
      "0 -- 0\n",
      "1 -- 1\n",
      "0 -- 0\n",
      "1 -- 1\n",
      "Took: 0.743571 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(100):\n",
    "        total_loss = 0\n",
    "        for x_i, y_i in next_batch(train_x.values, train_y.values):\n",
    "            _, l = sess.run(\n",
    "                [optimizer, \n",
    "                 loss],\n",
    "                feed_dict= \n",
    "                {X:x_i, \n",
    "                 Y:y_i}) \n",
    "            \n",
    "            total_loss += l  \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch {0}: {1}'.format(i, total_loss))\n",
    "            \n",
    "    print ('test' + '--'*20)\n",
    "    print ('predicted -- true')\n",
    "\n",
    "    for x_i, y_i in next_batch(test_x.values, test_y.values):\n",
    "        Y_pred = sess.run(\n",
    "            [Y_predicted],\n",
    "            feed_dict= \n",
    "            {X:x_i})\n",
    "        for index_i, Y_in_batch in enumerate(Y_pred[0]):\n",
    "#             print (Y_in_batch)\n",
    "            print ('{0} -- {1}'.format(np.argsort(Y_in_batch)[-1], y_i[index_i]))\n",
    "\n",
    "print('Took: %f seconds' %(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save  and restore model\n",
    "\n",
    "tf.train.Saver.save(sess, save_path, global_step=None...)\n",
    "\n",
    "\n",
    "tf.train.Saver.restore(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=50)\n",
    "# saver = tf.train.Saver({'variable': v1, 'v2': v2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 10.408232390880585\n",
      "Epoch 9: 7.42070198059082\n",
      "Epoch 14: 6.0516665279865265\n",
      "Epoch 19: 5.220244735479355\n",
      "Epoch 24: 4.623729318380356\n",
      "Epoch 29: 4.143933460116386\n",
      "Epoch 34: 3.738716259598732\n",
      "Epoch 39: 3.3843933939933777\n",
      "Epoch 44: 3.0637393295764923\n",
      "Epoch 49: 2.791569545865059\n",
      "Epoch 54: 2.5571112260222435\n",
      "Epoch 59: 2.354011930525303\n",
      "Epoch 64: 2.178238794207573\n",
      "Epoch 69: 2.026128336787224\n",
      "Epoch 74: 1.8946508169174194\n",
      "Epoch 79: 1.7808574810624123\n",
      "Epoch 84: 1.6820202842354774\n",
      "Epoch 89: 1.5960067920386791\n",
      "Epoch 94: 1.520504105836153\n",
      "Epoch 99: 1.454014390707016\n",
      "Took: 8.624159 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Step 8: train the model for 100 epochs\n",
    "    for i in range(100):\n",
    "        total_loss = 0\n",
    "        for x_i, y_i in next_batch(train_x.values, train_y.values, batch_size=10):\n",
    "            _, l = sess.run(\n",
    "                [optimizer, \n",
    "                 loss], \n",
    "                {X:x_i, \n",
    "                 Y:y_i}) \n",
    "            \n",
    "            total_loss += l  \n",
    "        if (i + 1) % 5 == 0:\n",
    "            print('Epoch {0}: {1}'.format(i, total_loss))\n",
    "            saver.save(sess, \n",
    "            './model',\n",
    "            global_step=i)\n",
    "\n",
    "\n",
    "print('Took: %f seconds' %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./iris/model_network/model-4\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './iris/model_network/model-4')\n",
    "    \n",
    "    print ('test' + '--'*20)\n",
    "    print ('predicted -- true')\n",
    "\n",
    "    for x_i, y_i in next_batch(test_x.values, test_y.values):\n",
    "        Y_pred = sess.run(\n",
    "            [Y_predicted],\n",
    "            feed_dict= \n",
    "            {X:x_i})\n",
    "        for index_i, Y_in_batch in enumerate(Y_pred[0]):\n",
    "#             print (Y_in_batch)\n",
    "            print ('{0} -- {1}'.format(np.argsort(Y_in_batch)[-1], y_i[index_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
